{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "data_raw = pd.read_csv('creditcard.csv')\n",
    "data = data_raw\n",
    "# print(data['Amount'].value_counts())\n",
    "#split data into x and y\n",
    "\n",
    "# y = data['Class']\n",
    "# del data['Class']\n",
    "\n",
    "# standardize values\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "\n",
    "y = data_raw['Class'] #collecting the Amount values\n",
    "data = np.delete(data, 30, axis=1) #not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done running model\n",
      "0:00:02.243824\n"
     ]
    }
   ],
   "source": [
    "#time terminal\n",
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "#first model to test - simple logitical regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#split into train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,y, test_size = 0.2)\n",
    "\n",
    "\n",
    "\n",
    "def logreg(X_train,X_test):\n",
    "\n",
    "    LR_model = LogisticRegression(max_iter = 250).fit(X_train, y_train)\n",
    "    print(\"Done running model\")\n",
    "    y_pred = LR_model.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "    \n",
    "y_pred = logreg(X_train,X_test)\n",
    "y_true = y_test.array\n",
    "\n",
    "flscore = f1_score(y_pred,y_test) #calculates the fl score for logistic regression\n",
    "\n",
    "# #find out costs\n",
    "# costs = \n",
    "\n",
    "# #find out costmax\n",
    "# costmax = \n",
    "\n",
    "# cost = 1 - costs/costmax\n",
    "\n",
    "print(datetime.now() - startTime)\n",
    "#flscore returns around 71%\n",
    "#cost returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5080363771627056\n",
      "0.5093925453814732\n",
      "0.6008995096444302\n",
      "0.560125238431448\n",
      "0.584033115698146\n",
      "0:00:09.010508\n"
     ]
    }
   ],
   "source": [
    "#time terminal\n",
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "#first model to test - simple logitical regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.metrics import f1_score, average_precision_score, precision_recall_curve\n",
    "\n",
    "def logreg(X_train,X_test):\n",
    "\n",
    "    LR_model = LogisticRegression(max_iter = 250).fit(X_train, y_train)\n",
    "    y_pred = LR_model.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "#split into train test\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_pred = logreg(X_train,X_test)\n",
    "    y_true = y_test.array\n",
    "    auprc = average_precision_score(y_test,y_pred)\n",
    "    print(auprc) #calculates the auprc\n",
    "\n",
    "    \n",
    "#after 5 iterations, we found f1score is 0.73\n",
    "\n",
    "print(datetime.now() - startTime)\n",
    "#AUPRC --> 0.55 (very good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618290173232241\n",
      "0.5467351331425208\n",
      "0.6380035608513857\n",
      "0.5535702099203442\n",
      "0.5499979807465551\n"
     ]
    }
   ],
   "source": [
    "#model 2 --> Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#model\n",
    "def dtc(X_train,X_test):\n",
    "\n",
    "    LR_model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "    y_pred = LR_model.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "#split into train test\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_pred = dtc(X_train,X_test)\n",
    "    y_true = y_test.array\n",
    "    auprc = average_precision_score(y_test,y_pred)\n",
    "    print(auprc) #AUPRC --> 0.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7459042354345622\n"
     ]
    }
   ],
   "source": [
    "#SMOTE technique -> most optimized Random Forest Classifier model:\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "#split into train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,y, test_size = 0.2)\n",
    "\n",
    "sm = SMOTE(random_state=12)\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "#Synthetic Minority Over-sampling Technique has been designed to generate new samples that are coherent with the minor class distribution.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(max_depth=None, min_samples_split=5)\n",
    "model.fit(x_train_res , y_train_res)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "auprc = average_precision_score(y_test,y_pred)\n",
    "print(auprc) #AUPRC --> 0.75, significantly more accurate than previous models (approx.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning hyperparameters of model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,y, test_size = 0.2)\n",
    "\n",
    "sm = SMOTE(random_state=12)\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "parameters = {'max_depth': [None,1,3,5,10],\n",
    "              'min_samples_split': [5,10],\n",
    "              'min_samples_leaf': [5, 10],\n",
    "             'n_estimators': [100,150,200]} #parameters that I want to adjust\n",
    "\n",
    "base_estimator = RandomForestClassifier()\n",
    "\n",
    "gs_rfc = GridSearchCV(base_estimator, param_grid = parameters)\n",
    "gs_rfc.fit(x_train_res, y_train_res)\n",
    "\n",
    "# y_pred = gs_rf.predict(X_test)\n",
    "\n",
    "# auprc = average_precision_score(y_test,y_pred)\n",
    "# print(auprc) #AUPRC --> 0.80, significantly more accurate than previous models (approx.)\n",
    "\n",
    "#max_depth = 1, 0.20; 10, 0.45\n",
    "#max_depth=None, min_samples_split=5, 0.7924; 10, 0.68; 3,0.74\n",
    "#max_depth=None, min_samples_split=5,min_samples_leaf=5; 0.69, 10, 0.66\n",
    "#max_depth=None, min_samples_split=5, min_samples_leaf = default (1), n_estimators = 150, 0.746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7052749292956164\n",
      "0.7335476448617553\n",
      "0.7465461234323701\n",
      "0.6954568373281006\n",
      "0.7311503175854879\n"
     ]
    }
   ],
   "source": [
    "#SMOTE technique -> most optimized Random Forest Classifier model:\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    sm = SMOTE(random_state=12)\n",
    "    x_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "    model = RandomForestClassifier(max_depth=None, min_samples_split=5)\n",
    "    model.fit(x_train_res , y_train_res)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test.array\n",
    "    \n",
    "    auprc = average_precision_score(y_test,y_pred)\n",
    "    print(auprc) #averages at around 0.73 AUPRC, which is very good for an unbalanced classification model of\n",
    "    #0.17%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
